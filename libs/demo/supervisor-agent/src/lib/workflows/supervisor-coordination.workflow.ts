import { Injectable } from '@nestjs/common';
import { 
  Workflow, 
  Node, 
  Edge,
  StreamToken,
  StreamEvent,
  StreamProgress,
  RequiresApproval,
  DeclarativeWorkflowBase,
  WorkflowState,
  Command,
  CommandType,
  AgentType,
  ApprovalRiskLevel,
  StreamEventType
} from '@anubis/nestjs-langgraph';

/**
 * Agent state interface for multi-agent coordination
 * Extends WorkflowState with supervisor-specific fields
 */
export interface SupervisorAgentState extends WorkflowState {
  task: string;
  complexity: 'low' | 'medium' | 'high';
  currentAgent?: string;
  nextAgent?: string;
  research?: string;
  analysis?: string;
  memories?: any[];
  confidence?: number;
  approved?: boolean;
  executionPath?: string[];
  metadata?: Record<string, any>;
}

/**
 * SupervisorCoordinationWorkflow - Demonstrates the FULL POWER of our infrastructure
 * 
 * This workflow leverages ALL our powerful modules:
 * - CheckpointModule: Automatic state persistence at each node
 * - MemoryModule: Contextual memory for agent decisions
 * - MultiAgentModule: Sophisticated agent coordination
 * - MonitoringModule: Real-time metrics and alerting
 * - TimeTravelModule: Debugging with state snapshots
 * - StreamingModule: Token, event, and progress streaming
 * - HITLModule: Human approval with risk assessment
 * 
 * Unlike basic implementations, this workflow automatically integrates
 * with all infrastructure services through the decorator pattern!
 */
@Injectable()
@Workflow({
  name: 'supervisor-coordination',
  pattern: 'supervisor',
  description: 'Multi-agent coordination with supervisor pattern',
  version: '1.0.0',
  streaming: {
    enabled: true,
    includeMetadata: true
  },
  hitl: {
    enabled: true,
    confidenceThreshold: 0.7
  },
  monitoring: {
    metrics: ['latency', 'token_usage', 'agent_performance'],
    alerts: ['high_latency', 'error_rate']
  },
  checkpoint: {
    enabled: true,
    strategy: 'after_each_node'
  },
  timeTravel: {
    enabled: true,
    maxSnapshots: 30
  }
})
export class SupervisorCoordinationWorkflow extends DeclarativeWorkflowBase<SupervisorAgentState> {
  
  /**
   * Supervisor node - Routes tasks to appropriate worker agents
   * Automatically uses MultiAgentCoordinatorService for intelligent routing
   */
  @Node({ 
    type: 'supervisor',
    description: 'Coordinate task routing to specialized agents',
    monitoring: { 
      trackDuration: true,
      trackTokenUsage: true 
    }
  })
  @StreamToken({ 
    enabled: true,
    bufferSize: 50,
    format: 'markdown'
  })
  @StreamEvent({
    events: [StreamEventType.NODE_START, StreamEventType.DECISION_MADE]
  })
  async supervisorNode(state: SupervisorAgentState): Promise<Command<SupervisorAgentState>> {
    console.log('üéØ Supervisor: Analyzing task complexity and routing...');
    
    // Retrieve context from MemoryModule automatically
    const memories = await this.retrieveMemories(state);
    
    // Analyze task complexity using LLM
    const analysis = await this.analyzeTaskComplexity(state.task, memories);
    
    // Update execution path for monitoring
    const executionPath = [...(state.executionPath || []), 'supervisor'];
    
    // Make routing decision based on complexity
    let nextAgent: string;
    let confidence = 0.5;
    
    if (analysis.complexity === 'high' || analysis.requiresResearch) {
      nextAgent = 'researcher';
      confidence = 0.8;
      console.log('üìö Routing to Researcher Agent for deep analysis');
    } else if (analysis.complexity === 'medium' || analysis.requiresAnalysis) {
      nextAgent = 'analyzer';
      confidence = 0.75;
      console.log('üìä Routing to Analyzer Agent for data analysis');
    } else {
      // Simple task - go directly to completion
      console.log('‚úÖ Simple task - proceeding to completion');
      return {
        type: CommandType.GOTO,
        goto: 'completion',
        update: {
          complexity: 'low',
          confidence: 0.9,
          executionPath,
          analysis: 'Task is straightforward and can be completed directly'
        }
      };
    }
    
    // Return routing command with state updates
    return {
      type: CommandType.GOTO,
      goto: nextAgent,
      update: {
        complexity: analysis.complexity as 'low' | 'medium' | 'high',
        nextAgent,
        confidence,
        executionPath,
        metadata: {
          ...state.metadata,
          supervisorAnalysis: analysis,
          routingDecision: nextAgent,
          timestamp: new Date().toISOString()
        }
      }
    };
  }
  
  /**
   * Researcher Agent - Conducts deep research using memory and tools
   * Integrates with MemoryModule for context and CheckpointModule for persistence
   */
  @Node({ 
    type: 'agent',
    agentType: AgentType.RESEARCHER,
    description: 'Conduct research and gather information',
    checkpoint: { 
      enabled: true,
      captureOutput: true 
    }
  })
  @StreamToken({ 
    enabled: true,
    bufferSize: 100,
    filter: {
      minLength: 2,
      excludeWhitespace: true
    }
  })
  @StreamProgress({
    enabled: true,
    granularity: 'detailed',
    includeETA: true
  })
  async researcherNode(state: SupervisorAgentState): Promise<Partial<SupervisorAgentState>> {
    console.log('üîç Researcher: Starting deep research on task...');
    
    // Retrieve relevant memories automatically via MemoryModule
    const memories = await this.retrieveMemories(state);
    console.log(`üìù Retrieved ${memories.length} relevant memories`);
    
    // Conduct research using LLM with context
    const research = await this.conductResearch(state.task, memories);
    
    // Store research results in memory for future use
    await this.storeMemory({
      content: research,
      metadata: {
        agent: 'researcher',
        task: state.task,
        timestamp: new Date().toISOString()
      }
    });
    
    // Update execution path
    const executionPath = [...(state.executionPath || []), 'researcher'];
    
    console.log('‚úÖ Research completed successfully');
    
    return {
      research,
      confidence: 0.85,
      executionPath,
      memories: [...memories, { role: 'researcher', content: research }],
      metadata: {
        ...state.metadata,
        researchCompleted: true,
        researchLength: research.length,
        memoryCount: memories.length
      }
    };
  }
  
  /**
   * Analyzer Agent - Analyzes research and provides insights
   * Uses MonitoringModule to track performance metrics
   */
  @Node({ 
    type: 'agent',
    agentType: AgentType.ANALYST,
    description: 'Analyze data and provide insights',
    monitoring: {
      customMetrics: ['analysis_depth', 'insight_quality']
    }
  })
  @StreamToken({ enabled: true })
  @StreamEvent({
    events: [StreamEventType.ANALYSIS_COMPLETE]
  })
  async analyzerNode(state: SupervisorAgentState): Promise<Partial<SupervisorAgentState>> {
    console.log('üìä Analyzer: Processing data and generating insights...');
    
    // Combine research and memories for analysis
    const context = {
      task: state.task,
      research: state.research || '',
      memories: state.memories || [],
      previousAnalysis: state.analysis
    };
    
    // Perform analysis using LLM
    const analysis = await this.performAnalysis(context);
    
    // Calculate confidence based on available data
    const confidence = this.calculateConfidence(state, analysis);
    
    // Update execution path
    const executionPath = [...(state.executionPath || []), 'analyzer'];
    
    console.log(`‚úÖ Analysis completed with ${(confidence * 100).toFixed(1)}% confidence`);
    
    return {
      analysis,
      confidence,
      executionPath,
      metadata: {
        ...state.metadata,
        analysisCompleted: true,
        analysisInsights: analysis.insights?.length || 0,
        confidenceScore: confidence
      }
    };
  }
  
  /**
   * Human Approval Node - HITL integration for critical decisions
   * Uses HumanApprovalService with risk assessment
   */
  @Node({ 
    type: 'human',
    description: 'Human review and approval checkpoint',
    timeout: 1800000 // 30 minutes
  })
  @RequiresApproval({
    confidenceThreshold: 0.8,
    riskThreshold: ApprovalRiskLevel.MEDIUM,
    riskAssessment: {
      enabled: true,
      factors: ['complexity', 'confidence', 'impact'],
      evaluator: (state: SupervisorAgentState) => ({
        level: state.complexity === 'high' ? 
          ApprovalRiskLevel.HIGH : 
          ApprovalRiskLevel.MEDIUM,
        factors: {
          complexity: state.complexity,
          confidence: state.confidence || 0,
          hasResearch: !!state.research,
          hasAnalysis: !!state.analysis
        },
        score: (state.confidence || 0.5) * (state.complexity === 'high' ? 0.7 : 0.9)
      })
    },
    escalationStrategy: 'timeout_approve',
    approvalMessage: (state: SupervisorAgentState) => 
      `Approve execution of: ${state.task}\nComplexity: ${state.complexity}\nConfidence: ${((state.confidence || 0) * 100).toFixed(1)}%`
  })
  async approvalNode(state: SupervisorAgentState): Promise<Partial<SupervisorAgentState>> {
    console.log('üë§ HITL: Awaiting human approval...');
    
    // This is automatically handled by HumanApprovalService
    // The decorator manages the approval workflow
    
    const executionPath = [...(state.executionPath || []), 'approval'];
    
    console.log('‚úÖ Approval received');
    
    return {
      approved: true,
      executionPath,
      metadata: {
        ...state.metadata,
        approvalReceived: true,
        approvalTimestamp: new Date().toISOString()
      }
    };
  }
  
  /**
   * Completion Node - Final node that summarizes the workflow
   * Uses TimeTravelService to create final snapshot
   */
  @Node({ 
    type: 'output',
    description: 'Workflow completion and summary',
    snapshot: true // Creates time-travel snapshot
  })
  @StreamProgress({
    enabled: true,
    message: 'Finalizing workflow results...'
  })
  async completionNode(state: SupervisorAgentState): Promise<Partial<SupervisorAgentState>> {
    console.log('üéØ Completion: Summarizing workflow results...');
    
    // Generate summary based on execution path
    const summary = await this.generateSummary(state);
    
    // Store final results in memory
    await this.storeMemory({
      content: summary,
      metadata: {
        type: 'workflow_completion',
        task: state.task,
        executionPath: state.executionPath,
        confidence: state.confidence,
        timestamp: new Date().toISOString()
      }
    });
    
    const executionPath = [...(state.executionPath || []), 'completion'];
    
    console.log('‚úÖ Workflow completed successfully!');
    
    return {
      summary,
      executionPath,
      completed: true,
      metadata: {
        ...state.metadata,
        completedAt: new Date().toISOString(),
        totalNodes: executionPath.length,
        finalConfidence: state.confidence
      }
    };
  }
  
  /**
   * Define workflow edges - routing between nodes
   */
  @Edge('START', 'supervisorNode')
  @Edge('supervisorNode', (state, result) => result?.goto || 'completion')
  @Edge('researcherNode', 'approvalNode')
  @Edge('analyzerNode', 'approvalNode')
  @Edge('approvalNode', 'completionNode')
  @Edge('completionNode', 'END')
  defineEdges() {
    // Edges are defined via decorators
  }
  
  // Helper methods that integrate with our infrastructure
  
  private async retrieveMemories(state: SupervisorAgentState): Promise<any[]> {
    // This would integrate with MemoryFacadeService
    // For demo, returning mock memories
    return state.memories || [];
  }
  
  private async storeMemory(entry: any): Promise<void> {
    // This would integrate with MemoryFacadeService
    console.log(`üíæ Storing memory: ${entry.metadata.type || 'general'}`);
  }
  
  private async analyzeTaskComplexity(task: string, memories: any[]): Promise<any> {
    // This would use LLM to analyze task
    // For demo, returning mock analysis
    return {
      complexity: task.length > 100 ? 'high' : 'medium',
      requiresResearch: task.includes('research') || task.includes('find'),
      requiresAnalysis: task.includes('analyze') || task.includes('compare'),
      confidence: 0.75
    };
  }
  
  private async conductResearch(task: string, memories: any[]): Promise<string> {
    // This would use LLM with tools for research
    return `Research findings for "${task}": 
    1. Key insight from domain analysis
    2. Relevant data points discovered
    3. Historical context from memories
    4. Recommendations based on research`;
  }
  
  private async performAnalysis(context: any): Promise<any> {
    // This would use LLM for deep analysis
    return {
      summary: 'Comprehensive analysis completed',
      insights: [
        'Pattern identified in data',
        'Correlation with previous cases',
        'Risk factors assessed'
      ],
      recommendations: [
        'Proceed with implementation',
        'Monitor key metrics',
        'Schedule follow-up review'
      ]
    };
  }
  
  private calculateConfidence(state: SupervisorAgentState, analysis: any): number {
    let confidence = 0.5;
    
    if (state.research) confidence += 0.2;
    if (state.memories && state.memories.length > 0) confidence += 0.1;
    if (analysis.insights && analysis.insights.length > 2) confidence += 0.15;
    if (state.approved) confidence += 0.05;
    
    return Math.min(confidence, 0.95);
  }
  
  private async generateSummary(state: SupervisorAgentState): Promise<string> {
    const steps = state.executionPath?.join(' ‚Üí ') || 'No path recorded';
    const confidence = ((state.confidence || 0) * 100).toFixed(1);
    
    return `
## Workflow Summary

**Task**: ${state.task}
**Complexity**: ${state.complexity}
**Execution Path**: ${steps}
**Final Confidence**: ${confidence}%

### Research Results
${state.research || 'No research conducted'}

### Analysis Insights
${state.analysis?.summary || 'No analysis performed'}

### Approval Status
${state.approved ? '‚úÖ Approved by human reviewer' : '‚è≠Ô∏è Automated completion'}

### Conclusion
Workflow completed successfully with all infrastructure services integrated:
- ‚úÖ CheckpointModule: State persisted at each node
- ‚úÖ MemoryModule: Context retrieved and stored
- ‚úÖ MultiAgentModule: Agents coordinated effectively
- ‚úÖ MonitoringModule: Metrics tracked throughout
- ‚úÖ TimeTravelModule: ${state.executionPath?.length || 0} snapshots available
- ‚úÖ StreamingModule: Real-time updates delivered
- ‚úÖ HITLModule: Human approval integrated

This demonstrates the POWER of our NestJS-LangGraph infrastructure!
    `.trim();
  }
}