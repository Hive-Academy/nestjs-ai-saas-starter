# =============================================================================
# NestJS AI SaaS Starter - Environment Configuration
# =============================================================================
# Copy this file to .env and update the values according to your setup
# =============================================================================

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
NODE_ENV=development
PORT=3000
LOG_LEVEL=info

# Application name and version (used in health checks and monitoring)
APP_NAME=nestjs-ai-saas-starter
APP_VERSION=1.0.0

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Neo4j Graph Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j
NEO4J_MAX_POOL_SIZE=100
NEO4J_CONNECTION_TIMEOUT=60000
NEO4J_HEALTH_CHECK=true
NEO4J_RETRY_ATTEMPTS=5
NEO4J_RETRY_DELAY=5000

# ChromaDB Vector Database
CHROMADB_HOST=localhost
CHROMADB_PORT=8000
CHROMADB_SSL=false
CHROMADB_URL=http://localhost:8000
CHROMADB_TENANT=default_tenant
CHROMADB_DATABASE=default_database
CHROMADB_BATCH_SIZE=100
CHROMADB_MAX_RETRIES=3
CHROMADB_RETRY_DELAY=1000

# Redis Cache
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# =============================================================================
# AI SERVICE API KEYS
# =============================================================================

# OpenAI (Optional - when using OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_openai_org_id_here

# Cohere (Optional - alternative embedding provider)
COHERE_API_KEY=your_cohere_api_key_here

# HuggingFace (Optional - leave empty for public models)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Anthropic (Optional - alternative LLM provider)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google AI (Optional - alternative LLM provider)
GOOGLE_AI_API_KEY=your_google_ai_api_key_here

# =============================================================================
# LOCAL MODEL CONFIGURATION (Ollama)
# =============================================================================

# Ollama Configuration for Local LLM
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
# Alternative models: mistral, codellama, neural-chat, starling-lm, etc.

# Ollama Model Parameters
OLLAMA_TEMPERATURE=0.7
OLLAMA_NUM_PREDICT=256
OLLAMA_TOP_K=40
OLLAMA_TOP_P=0.9

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================

# Default embedding provider (openai, cohere, huggingface, custom)
DEFAULT_EMBEDDING_PROVIDER=huggingface

# OpenAI Embedding Models (when using OpenAI)
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
# Alternatives: text-embedding-3-small, text-embedding-3-large

# Cohere Embedding Models (when using Cohere)
COHERE_EMBEDDING_MODEL=embed-english-v3.0
# Alternatives: embed-multilingual-v3.0, embed-english-light-v3.0

# HuggingFace Embedding Models (Default - Local/Free)
HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Alternatives: 
# - sentence-transformers/all-mpnet-base-v2 (higher quality, slower)
# - sentence-transformers/paraphrase-MiniLM-L6-v2 (good for paraphrasing)
# - sentence-transformers/multi-qa-MiniLM-L6-cos-v1 (optimized for Q&A)

# HuggingFace Configuration
HUGGINGFACE_USE_SERVERLESS=false  # Use local inference
HUGGINGFACE_WAIT_FOR_MODEL=true   # Wait for model to load

# =============================================================================
# LLM CONFIGURATION
# =============================================================================

# Default LLM provider (ollama, openai, anthropic, google, cohere)
DEFAULT_LLM_PROVIDER=ollama

# OpenAI Models (when using OpenAI)
OPENAI_MODEL=gpt-4
# Alternatives: gpt-3.5-turbo, gpt-4-turbo, gpt-4o

# Anthropic Models (when using Anthropic)
ANTHROPIC_MODEL=claude-3-sonnet-20240229
# Alternatives: claude-3-haiku-20240307, claude-3-opus-20240229

# Google AI Models (when using Google)
GOOGLE_AI_MODEL=gemini-pro
# Alternatives: gemini-pro-vision

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT Configuration (if using authentication)
JWT_SECRET=your_jwt_secret_here_make_it_long_and_random
JWT_EXPIRES_IN=24h

# CORS Configuration
CORS_ORIGIN=http://localhost:3000,http://localhost:4200
CORS_CREDENTIALS=true

# Rate Limiting
RATE_LIMIT_TTL=60
RATE_LIMIT_LIMIT=100

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================

# Health Check Configuration
HEALTH_CHECK_TIMEOUT=5000
HEALTH_CHECK_INTERVAL=30000

# Metrics and Tracing (Optional)
METRICS_ENABLED=true
TRACING_ENABLED=false
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Development Features
DEV_MODE=true
DEBUG_MODE=false
SWAGGER_ENABLED=true

# Hot Reload
WATCH_MODE=true

# =============================================================================
# PRODUCTION CONFIGURATION
# =============================================================================
# These settings are typically overridden in production environments

# Production Database URLs (override development settings)
# NEO4J_URI=bolt://neo4j-prod:7687
# CHROMADB_URL=http://chromadb-prod:8000
# REDIS_URL=redis://redis-prod:6379

# Production Security
# JWT_SECRET=your_production_jwt_secret_here
# CORS_ORIGIN=https://yourdomain.com

# Production Monitoring
# SENTRY_DSN=your_sentry_dsn_here
# NEW_RELIC_LICENSE_KEY=your_new_relic_key_here

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================
# These are used when running with Docker Compose

# Docker service names (used in docker-compose.yml)
DOCKER_NEO4J_HOST=neo4j
DOCKER_CHROMADB_HOST=chromadb
DOCKER_REDIS_HOST=redis

# Docker ports
DOCKER_NEO4J_PORT=7687
DOCKER_CHROMADB_PORT=8000
DOCKER_REDIS_PORT=6379

# =============================================================================
# TESTING CONFIGURATION
# =============================================================================

# Test Database Configuration
TEST_NEO4J_URI=bolt://localhost:7688
TEST_CHROMADB_URL=http://localhost:8001
TEST_REDIS_URL=redis://localhost:6380

# Test API Keys (use test/mock keys for testing)
TEST_OPENAI_API_KEY=test_openai_key
TEST_COHERE_API_KEY=test_cohere_key

# =============================================================================
# LIBRARY PUBLISHING CONFIGURATION
# =============================================================================
# These are used for NPM publishing (typically set in CI/CD)

# NPM Configuration
# NPM_TOKEN=your_npm_token_here
# NPM_REGISTRY=https://registry.npmjs.org/

# GitHub Configuration
# GITHUB_TOKEN=your_github_token_here

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable/disable specific features
FEATURE_VECTOR_SEARCH=true
FEATURE_GRAPH_QUERIES=true
FEATURE_AI_WORKFLOWS=true
FEATURE_STREAMING=true
FEATURE_HITL=true

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# Connection Pool Sizes
NEO4J_MAX_CONNECTION_POOL_SIZE=50
REDIS_MAX_CONNECTIONS=10

# Batch Processing
CHROMADB_BATCH_SIZE=100
EMBEDDING_BATCH_SIZE=50

# Timeouts (in milliseconds)
DATABASE_TIMEOUT=30000
API_TIMEOUT=10000
EMBEDDING_TIMEOUT=30000

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log Levels: error, warn, info, debug, verbose
LOG_LEVEL=info

# Log Formats: json, simple, combined
LOG_FORMAT=json

# Log Destinations
LOG_TO_FILE=false
LOG_FILE_PATH=./logs/app.log
LOG_TO_CONSOLE=true

# =============================================================================
# NOTES
# =============================================================================
# 1. Never commit the actual .env file to version control
# 2. Use strong, unique passwords and API keys in production
# 3. Regularly rotate API keys and secrets
# 4. Use environment-specific configuration files for different deployments
# 5. Consider using a secrets management service in production
# =============================================================================
